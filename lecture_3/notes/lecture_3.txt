1) Searching
- formula would follow a pattern similar to
    - for i in range 0 to n-1
    - each iteration will 'search' through the ith element

2) Big O
- what is the efficiency of your code?
- O(n) --> Order of n
- O(n/2) --> Order of n divided by 2
- O(log2n) --> Oder of log n
- Most popular Orders or "running time"
    - O(n^2) --> Quadratic search --> looks like a steep slope, usually a nested loop and will conitnually get slower, (SLOWEST)
    - O(n log n)
    - O(n) --> Linear Search --> as n grows, the number of operations it takes to calculate will also grow looks like "/"
    - O(log n) --> Binary Search
    - O(1) --> as n grows, the number of operations stays the same. Looks like "---" (FASTEST)
- All Big O algorithms can be replaced by Omega --> opposite of Big O where it tracks the longest method of solving
    - Linear search and binary search would be omega(1)
- BIG O Tips
    - Constants do not matter
        - O(2n) --> O(n)
        - 0(500) --> O(1)
        - o(13n^2) --> O(n^2)
    - Smaller terms dont matter
        - O(n +10) --> O(n)
        - O(1000n + 50) --> O(n)
        - O(n^2 + 5n + 8) --> O(n^2)
    - Arithmetic operations are constant
    - Variable Assignment is constant
    - Accessing elements in an array are constant
    - in a loop, a complexity is the length of the loop x complexity of whatever happens inside of the loop


---------------Shorts-------------------
Linear Search
- the algorithm is to iterate across the array from left to right, searching for a specified element
--> start at the first element -->if found, stop --> if not found, move to the next element
--> Worst case scenario --> we search through every single element before finding/not finding it --> O(n)
--> Best case scenario --> we find it as the first element of the array --> Omega(1)



Binary Search
- divide and conquer --> reduce the search area by half each time, trying to find a target number
--> the array MUST be sorted first, else we cannot make an assumption as to which half the element is in
--> Pseudocode
    - continue to divide until the subarray is of size(length) 0
    - calculate the middle point of each subarray
    - if the target is at the middle of the subarray, stop the function
    - otherwise, if the element is less that the element at the middle, halve the area to the left of the middle
    - or if the element is greater than the element at the middle, halve the area to the right of the middle
--> worst case scenario --> either the element doesnt exist or we continue to halve the array until the element is the last result --> O(logn)
--> Best case scenario --> the element is at the middle of the full array, and found immediately --> Omega(1)



Bubble Sort
- algorithm moves higher values elements to the right and lower value elements to the left
--> Pseudocode
    - set a swap counter to a non-zero value
        - set swap counter to 0
        - if two adjacent elements are not in order, swap them and increment 1 to the swap counter
        - then go back to top of the function until an entire iteration of the array returns a swap counter as 0
--> worst case scenario --> the array is completely in reverse order, where n iterations is at its max --> O(n2)
--> Best Case scenario --> the array is perfectly sorted, and no swaps in the first iteration --> Omega(n)



Selection Sort
- algorithm is to find the smallest unsorted element and add it to the end of the sorted list
--> Pseudocode
    - repeat until no unsorted element remains
        - search the unsorted part of the array to find the smallest value
        - swap the smallestvalue with the first element of the unsorted array
--> Worst case scenario --> the array is completely in reverse order, sorting each element repeating n times --> O(n2)
--> Best Case scenario --> the array is already sorted from min to max, but we still have to run each element once either way --> Omega(n2)



Insertion Sort
- algorithm to build your sorted array in place, shifting elements out of the wau if necessary to make room as you go
--> Pseudocode
    - call the first element of the array "sorted"
        - look at the next "unsorted" element. Insert into the "sorted" portion by shifting the number of elements
        - '5' 2 1 3 6 4 --> '2' '5' 1 3 6 4 --> '1' '2' '5' 3 6 4 --> '1' '2' '3' '5' 6 4 --> etc
--> worst case scenario --> if the array is in reverse order, shifting each n by n positions each insertion, no attaching elements to the
    end of the "sorted array" --> O(n2)
--> Best case scenario --> shifted through the array once, each element is 'attached' to the end of the "sorted array" --> Omega(n)



Recursion **IMPORTANT**
- Definition --> an implementation of an algorithm as being particularly "elegant" if it solves a problem in a way that is both
interesting and easy to visualize
    --> Defined --> a function that, as part of its execution, invokes itself
- Factorial function n! --> multiply all numbers less than or equal to the n integer --> fact(n) in programming
Example:
    fact(1) = 1, fact(2) = 2 * 1, fact(3) = 3 * 2 * 1
    OR
    fact(1) = 1, fact(2) = 2 * fact(1), fact(3) = 3 * fact(2), fact(4) = 4 * fact(3)
- This means that factorial is --> fact(n) = n * fact(n-1)
- Recursion --> Pseudocode Parts
    - Part 1: Establish a Base Case to solve the one-off/edge cases that might occur in the function
        --> The base case is MAINLY used to trigger a termination command when satisfied
        - Example: fact(1) = 1 is an example of a base case
    - Part 2: Establish a recursive case, where the recursion wiill actually occur
- Recursion skeleton:
            int fact(int n) ------->.           int recursion_fact(int n) ------->  int regular_loop_fact(int n)
            {                                   {                                   {
                // base case. ------->              if (n == 1)                         int product = 1;
                                                    {                                   while (n > 0)
                                                        return 1;                       {
                                                    }                                       product *= n;
                                                                                            n--;
                                                    else                                }
                // recursive case. ------->         {                                   return product;
                                                        return n * fact(n-1)        }
                                                    }

            }                                   }
--> Explanation: with a fact(4), the recursive function will go as follows
    - Find fact(4)
    - fact(4) = 4*fact(3)
    - fact(3) = 3*fact(2)
    - fact(2) = 2*fact(1)
    - fact(1) = 1 --> This is our base case. The factorials above then initiate and resolve
    - fact(2) = 2 * 1 = 2
    - fact(3) = 3*2 = 6
    - fact(4) = 4*6 = 24 --> Answer

--> Tip: it is ok to have multiple base cases to exit the recursive function with multiple satisfiable solutions

- Collatz conjecture --> it is possible to return "back to 1" by following the below steps
    - if n == 1, stop
    - if n is even, n/2 and repeat (recursion)
    - if n is odd, 3n+1 and repeat (recursion)

int collatz(int n)
{
    // Establish the base case
    if (n == 1)
    {
        return 0;
    }

    // Recursion if Even
    else if ((n%2) == 0)
    {
        return 1 + collatz(n/2);
    }

    // Recursion if Odd
    {
        return 1 + collatz(3*n + 1);
    }
}




Merge Sort
- algorithm to sort smaller arrays, then combine those subarrays in sorted order
- this type of sorting uses RECURSION
--> Pseudocode
    - sort the left half of the array
    - sort the right half of the array
    - merge the subarrays
--> worst case scenario --> each split array will need to be continually split over and over --> O(n log n)
--> best case scenario --> the array is perfectly sorted, but still needs to split --> Omega(n log n)




Algorithm Summary:

- Selection sort: find the smallest unsorted element in the array and swap it with the first unsorted element in the array
    - worst O(n2)
    - best Omega(n2)
- Bubble sort: swap adjacent pairs where the smallest element in the pair to the left
    - worst O(n2)
    - best Omega(n)
- insertion sort: proceed left to right in the array, shifting elements as necessary to insert each into the correct order
    - worst O(n2)
    - best Omega(n)
- Merge sort: split and merge the array into subarrays
    - worst O(n log n)
    - best Omega(n log n)
- Linear search: iterating across the array from left to right to find the element
    - worst O(n)
    - best Omega(1)
- Binary Search: requires a sorted array. divide and conquer, split the array and elminate the halves that are certain to not hold the element
    - worst O(logn)
    - best O(1)